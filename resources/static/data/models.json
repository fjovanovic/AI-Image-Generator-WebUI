{
    "stabilityai/sdxl-turbo": {
        "link": "https://huggingface.co/stabilityai/sdxl-turbo",
        "info": "SDXL-Turbo is a fast generative text-to-image model that can synthesize photorealistic images from a text prompt in a single network evaluation. A real-time demo is available [here](http://clipdrop.co/stable-diffusion-turbo). \n\nSDXL-Turbo is a distilled version of [SDXL 1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0), trained for real-time synthesis. SDXL-Turbo is based on a novel training method called Adversarial Diffusion Distillation (ADD) (see the [technical report](https://stability.ai/research/adversarial-diffusion-distillation)), which allows sampling large-scale foundational image diffusion models in 1 to 4 steps at high image quality. This approach uses score distillation to leverage large-scale off-the-shelf image diffusion models as a teacher signal and combines this with an adversarial loss to ensure high image fidelity even in the low-step regime of one or two sampling steps.\n\nPreferably, the model generates images of size `512x512` but higher image sizes work as well"
    },
    "CompVis/stable-diffusion-v1-1": {
        "link": "https://huggingface.co/CompVis/stable-diffusion-v1-1",
        "info": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. For more information about how Stable Diffusion functions, please have a look at [Stable Diffusion with Diffusers blog](https://huggingface.co/blog/stable_diffusion).\n\n**The Stable-Diffusion-v1-1** was trained on 237,000 steps at resolution `256x256` on [laion2B-en](https://huggingface.co/datasets/laion/relaion2B-en-research-safe), followed by 194,000 steps at resolution `512x512` on [laion-high-resolution](https://huggingface.co/datasets/laion/laion-high-resolution) (170M examples from LAION-5B with resolution `>= 1024x1024`). For more information, please refer to [Training](https://huggingface.co/CompVis/stable-diffusion-v1-1#training).\n\nThis weights here are intended to be used with the Diffusers library. If you are looking for the weights to be loaded into the CompVis Stable Diffusion codebase, [come here](https://huggingface.co/CompVis/stable-diffusion-v-1-1-original).\n\nWhile the capabilities of image generation models are impressive, they can also reinforce or exacerbate social biases. Stable Diffusion v1 was trained on subsets of [LAION-2B(en)](https://laion.ai/blog/laion-5b/), which consists of images that are primarily limited to English descriptions. Texts and images from communities and cultures that use other languages are likely to be insufficiently accounted for. This affects the overall output of the model, as white and western cultures are often set as the default. Further, the ability of the model to generate content with non-English prompts is significantly worse than with English-language prompts.\n\nCheckpoints:\n   - <u>stable-diffusion-v1-1</u>: 237,000 steps at resolution `256x256` on [laion2B-en](https://huggingface.co/datasets/laion/relaion2B-en-research-safe). 194,000 steps at resolution `512x512` on [laion-high-resolution](https://huggingface.co/datasets/laion/laion-high-resolution) (170M examples from LAION-5B with resolution `>= 1024x1024`)."
    },
    "CompVis/stable-diffusion-v1-2": {
        "link": "https://huggingface.co/CompVis/stable-diffusion-v1-2",
        "info": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. For more information about how Stable Diffusion functions, please have a look at [Stable Diffusion with Diffusers blog](https://huggingface.co/blog/stable_diffusion).\n\n**The Stable-Diffusion-v1-2** checkpoint was initialized with the weights of the [Stable-Diffusion-v1-1](https://huggingface.co/CompVis/stable-diffusion-v1-1) checkpoint and subsequently fine-tuned on 515,000 steps at resolution `512x512` on \"laion-improved-aesthetics\" (a subset of laion2B-en, filtered to images with an original size `>= 512x512`, estimated aesthetics score `> 5.0`, and an estimated watermark probability `< 0.5`. For more information, please refer to [Training](https://huggingface.co/CompVis/stable-diffusion-v1-2#training).\n\nThis weights here are intended to be used with the Diffusers library. If you are looking for the weights to be loaded into the CompVis Stable Diffusion codebase, [come here](https://huggingface.co/CompVis/stable-diffusion-v-1-2-original).\n\nWhile the capabilities of image generation models are impressive, they can also reinforce or exacerbate social biases. Stable Diffusion v1 was trained on subsets of [LAION-2B(en)](https://laion.ai/blog/laion-5b/), which consists of images that are primarily limited to English descriptions. Texts and images from communities and cultures that use other languages are likely to be insufficiently accounted for. This affects the overall output of the model, as white and western cultures are often set as the default. Further, the ability of the model to generate content with non-English prompts is significantly worse than with English-language prompts.\n\nCheckpoints:\n   - <u>stable-diffusion-v1-2</u>: Resumed from `stable-diffusion-v1-1`. 515,000 steps at resolution `512x512` on \"laion-improved-aesthetics\" (a subset of laion2B-en, filtered to images with an original size `>= 512x512`, estimated aesthetics score `> 5.0`, and an estimated watermark probability `< 0.5`. The watermark estimate is from the LAION-5B metadata, the aesthetics score is estimated using an [improved aesthetics estimator](https://github.com/christophschuhmann/improved-aesthetic-predictor))."
    },
    "CompVis/stable-diffusion-v1-3": {
        "link": "https://huggingface.co/CompVis/stable-diffusion-v1-3",
        "info": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. For more information about how Stable Diffusion functions, please have a look at [Stable Diffusion with Diffusers blog](https://huggingface.co/blog/stable_diffusion).\n\n**The Stable-Diffusion-v1-3** checkpoint was initialized with the weights of the [Stable-Diffusion-v1-2](https://huggingface.co/steps/huggingface.co/CompVis/stable-diffusion-v1-2) checkpoint and subsequently fine-tuned on 195,000 steps at resolution `512x512` on \"laion-improved-aesthetics\" and 10 % dropping of the text-conditioning to improve [classifier-free guidance sampling](https://arxiv.org/abs/2207.12598). For more information, please refer to [Training](https://huggingface.co/CompVis/stable-diffusion-v1-3#training).\n\nThis weights here are intended to be used with the Diffusers library. If you are looking for the weights to be loaded into the CompVis Stable Diffusion codebase, [come here](https://huggingface.co/CompVis/stable-diffusion-v-1-3-original)\n\nWhile the capabilities of image generation models are impressive, they can also reinforce or exacerbate social biases. Stable Diffusion v1 was trained on subsets of [LAION-2B(en)](https://laion.ai/blog/laion-5b/), which consists of images that are primarily limited to English descriptions. Texts and images from communities and cultures that use other languages are likely to be insufficiently accounted for. This affects the overall output of the model, as white and western cultures are often set as the default. Further, the ability of the model to generate content with non-English prompts is significantly worse than with English-language prompts.\n\nCheckpoints:\n   - <u>stable-diffusion-v1-3</u>: Resumed from `stable-diffusion-v1-2`. 195,000 steps at resolution `512x512` on \"laion-improved-aesthetics\" and 10 % dropping of the text-conditioning to improve [classifier-free guidance sampling](https://arxiv.org/abs/2207.12598)."
    },
    "CompVis/stable-diffusion-v1-4": {
        "link": "https://huggingface.co/CompVis/stable-diffusion-v1-4",
        "info": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. For more information about how Stable Diffusion functions, please have a look at [Stable Diffusion with ðŸ§¨Diffusers blog](https://huggingface.co/blog/stable_diffusion).\n\n**The Stable-Diffusion-v1-4** checkpoint was initialized with the weights of the [Stable-Diffusion-v1-2](https://huggingface.co/steps/huggingface.co/CompVis/stable-diffusion-v1-2) checkpoint and subsequently fine-tuned on 225k steps at resolution 512x512 on \"laion-aesthetics v2 5+\" and 10% dropping of the text-conditioning to improve classifier-free guidance sampling.\n\nThis weights here are intended to be used with the Diffusers library. If you are looking for the weights to be loaded into the CompVis Stable Diffusion codebase, [come here](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original).\n\nWhile the capabilities of image generation models are impressive, they can also reinforce or exacerbate social biases. Stable Diffusion v1 was trained on subsets of [LAION-2B(en)](https://laion.ai/blog/laion-5b/), which consists of images that are primarily limited to English descriptions. Texts and images from communities and cultures that use other languages are likely to be insufficiently accounted for. This affects the overall output of the model, as white and western cultures are often set as the default. Further, the ability of the model to generate content with non-English prompts is significantly worse than with English-language prompts.\n\nThe intended use of this model is with the [Safety Checker](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py) in Diffusers. This checker works by checking model outputs against known hard-coded NSFW concepts. The concepts are intentionally hidden to reduce the likelihood of reverse-engineering this filter. Specifically, the checker compares the class probability of harmful concepts in the embedding space of the `CLIPTextModel` _after generation_ of the images. The concepts are passed into the model with the generated image and compared to a hand-engineered weight for each NSFW concept.\n\nCheckpoints:\n   - <u>stable-diffusion-v1-4</u>: Resumed from `stable-diffusion-v1-2`.225,000 steps at resolution `512x512` on \"laion-aesthetics v2 5+\" and 10 % dropping of the text-conditioning to improve [classifier-free guidance sampling](https://arxiv.org/abs/2207.12598)."
    },
    "runwayml/stable-diffusion-v1-5": {
        "link": "https://huggingface.co",
        "info": "Missing"
    }
}